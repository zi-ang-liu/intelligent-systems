# Differential Evolution

Differential Evolution (DE) is a population-based optimization algorithm that is particularly effective for continuous optimization problems. 

This algorithm has the following steps:
1. **Initialization**: Generate an initial population of candidate solutions randomly within the defined bounds.
2. **Mutation**: Create new candidate solutions by combining existing ones.
3. **Crossover**: Combine the mutated candidates with the original ones to create a new population.
4. **Selection**: Evaluate the new candidates and select the best ones to form the next generation.

## Initialization

Consider a function $f: \mathbb{R}^n \to \mathbb{R}$ that we want to minimize over a bounded search space $\mathcal{X} = \{\mathbf{x} \in \mathbb{R}^n | \mathbf{x}_{\text{min}} \leq \mathbf{x} \leq \mathbf{x}_{\text{max}}\}$, where $\mathbf{x}_{\text{min}}$ and $\mathbf{x}_{\text{max}}$ are the lower and upper bounds of the search space, respectively.

Let $\mathbf{x}_{i,t} \in \mathcal{X}$ be the $i$-th solution in the population at generation $t$. The initial population can be generated randomly by the following equation:

$$
\mathbf{x}_{i,0} = \mathbf{x}_{\text{min}} + \mathbf{r}_{i} \cdot (\mathbf{x}_{\text{max}} - \mathbf{x}_{\text{min}}), \quad i = 1, 2, \ldots, N
$$

where $N$ is the population size and $\mathbf{r}_{i}$ is a vector of random numbers uniformly distributed in the range $[0, 1]$.

```python
import numpy as np

def initialize_population(n, m, x_min, x_max):
    """
    Initialize a population
    
    Parameters
    ----------
    n : int
        Population size
    m : int
        Number of decision variables
    x_min : array-like
        Lower bounds of the decision variables
    x_max : array-like
        Upper bounds of the decision variables
    """
    return np.random.uniform(x_min, x_max, (n, m))

# Example usage
n = 5  # population size
m = 2  # number of decision variables
x_min = np.array([-5, -5])  # lower bounds
x_max = np.array([5, 5])    # upper bounds
population = initialize_population(n, m, x_min, x_max)
print(population)
```

## Mutation

In the mutation operation, a new candidate solution is generated by adding the weighted difference between two randomly selected solutions to a third solution. The mutation can be expressed mathematically as follows:

$$
\mathbf{v}_{i,t} = \mathbf{x}_{r_1,t} + F \cdot (\mathbf{x}_{r_2,t} - \mathbf{x}_{r_3,t}), \quad i = 1, 2, \ldots, N
$$

where $\mathbf{v}_{i,t}$ is the mutated vector for the $i$-th solution at generation $t$, $F$ is a scaling factor, and $\mathbf{x}_{r_1,t}$, $\mathbf{x}_{r_2,t}$, and $\mathbf{x}_{r_3,t}$ are three distinct randomly selected solutions from the population. 

```python
def mutation(pop, F):
    """
    Perform mutation operation
    
    Parameters
    ----------
    pop : array-like
        Current population
    F : float
        Scaling factor
    """
    n_pop, n_dim = pop.shape
    random_idx = np.random.randint(0, n_pop, (n_pop, 3))
    r1, r2, r3 = random_idx[:, 0], random_idx[:, 1], random_idx[:, 2]
    v = pop[r1, :] + F * (pop[r2, :] - pop[r3, :])
    return v

# Example usage
F = 0.8  # scaling factor
pop = initialize_population(n, m, x_min, x_max)
mutation = mutation(pop, F)
print(mutation)
```

The obtained mutated vector $\mathbf{v}_{i,t}$ may exceed the bounds of the search space. To ensure that the mutated vector remains within the bounds, we can apply a simple repairing operation:

```python
def repair_vector(v, x_min, x_max):
    """
    Repair the mutated vector to ensure it is within bounds
    
    Parameters
    ----------
    v : array-like
        Mutated vector
    x_min : array-like
        Lower bounds of the decision variables
    x_max : array-like
        Upper bounds of the decision variables
    """
    return np.clip(v, x_min, x_max)

# Example usage
v = np.array([10, -10])  # mutated vector
x_min = np.array([-5, -5])  # lower bounds
x_max = np.array([5, 5])    # upper bounds
repaired_v = repair_vector(v, x_min, x_max)
print(repaired_v)
```

## Crossover

The crossover operation combines the mutated vector $\mathbf{v}_{i,t}$ with the original solution $\mathbf{x}_{i,t}$ to create a trial vector $\mathbf{u}_{i,t}$. The binomial crossover is commonly used:

$$
\mathbf{u}_{i,t} = \begin{cases}
\mathbf{v}_{i,t} & \text{if } j = j_{rand} \text{ or } r_j < CR \\
\mathbf{x}_{i,t} & \text{otherwise}
\end{cases}
$$

where $CR$ is the crossover probability, $j_{rand}$ is a randomly chosen index, and $r_j$ is a random number uniformly distributed in the range $[0, 1]$.

```python
def crossover(pop, v, CR):
    """
    Perform crossover operation
    
    Parameters
    ----------
    pop : array-like
        Current population
    v : array-like
        Mutated vector
    CR : float
        Crossover probability
    """
    